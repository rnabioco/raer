---
title: "RNA editing during viral infection"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{chikv-editing}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette is an analysis of RNA editing 

```{r libs, message=FALSE}
library(raer)
library(tidyverse)
library(fs)

library(BiocParallel)
library(SummarizedExperiment)
library(plyranges)
library(rtracklayer)
library(GenomicFeatures)
```

```{r setup_common_data}
ext_path = path('~/projects/raer-chikv')
samples = c('A1','A2','A3', 'M1', 'M2', 'M3')

fns = list(
  bams    = path(ext_path, 'bam', str_c( samples, '.bam')),
  bais    = path(ext_path, 'bam', str_c(samples, '.bam.bai')),
  fasta   = path(ext_path, 'ref', 'mm10_CHIKV_AF15561.fa.gz'),
  rmsk_db = path(ext_path, 'ref', 'rmsk.mm10.bed.gz'),
  snp_db  = path(ext_path, 'ref', 'snp142.mm10.bed.gz'),
  gtf     = path(ext_path, 'ref', 'gencode.knownGene.mm10.gtf.gz')
)
```


```{r run_pileup, eval = FALSE}
fp <- FilterParam(
  # min depth of 3 for each replicate
  min_nucleotide_depth = 3,
  min_base_quality = 30,
  min_mapq = rep(255, 6),
  library_type = rep("fr-first-strand", 6),
  trim_5p = 5,
  trim_3p = 5,
  indel_dist = 4,
  homopolymer_len = 6,
  max_mismatch_type = c(3, 3),
  min_read_bqual = c(0.25, 20),
  only_keep_variants = rep(TRUE, 6)
)

bpp <- SnowParam(workers = 6)
plps <- get_pileup(
  fns$bams,
  fafile = fns$fasta,
  filterParam = fp,
  BPPARAM = bpp
)

names(plps) <- c('A1','A2','A3','M1','M2','M3')
plps

all_rse <- create_se(plps)

chikv_rse <- subsetByOverlaps(
  all_rse,
  filter(rowRanges(all_rse), seqnames == 'CHIKV_AF15561')
)

mm_rse <- subsetByOverlaps(
  all_rse,
  filter(rowRanges(all_rse), seqnames != 'CHIKV_AF15561')
)

# remove multi-allelics now, they're not much use later
all_rse <- remove_multiallelic(all_rse)

saveRDS(all_rse, path(ext_path, '/rds/all_rse.rds', compress = 'xz'))
saveRDS(mm_rse, path(ext_path, '/rds/mm_rse.rds', compress = 'xz'))
saveRDS(chikv_rse, path(ext_path, '/rds/chikv_rse.rds', compress = 'xz'))
```

```{r load_rds, eval = FALSE}
all_rse <- readRDS(path(ext_path, '/rds/all_rse.rds'))
mm_rse <- readRDS(path(ext_path, '/rds/mm_rse.rds'))
chikv_rse <- readRDS(path(ext_path, '/rds/chikv_rse.rds'))
```

## Filters

### threshold 

```{r filter_fxn}
# helper function to filter samples within each replicate
filter_replicates <- function(x, thresh = 0, n_rep = 3) {
  
  mocks <- c('M1', 'M2', 'M3')
  virus <- c('A1', 'A2', 'A3')

  keep_mocks <- rowSums(x[, mocks] >= thresh) == n_rep
  keep_virus <- rowSums(x[, virus] >= thresh) == n_rep 

  keep_all <- keep_mocks | keep_virus
  
  x[keep_all, ]
}
```

The order here is important, the first `nVar` filter removes a large chunk of the data, so we only compute the next step on ~10% of the sites.

```{r filter_mm}
# filter for at least 3 reads at each site every sample in the replicates.
# this removes a large chunk of the data that is low coverage, ~90% or so 
mm_rse_filt <- filter_replicates(
  assay(mm_rse, "nVar")[, 1:6],
  thresh = 3,
  n_rep = 3
)

# Next, remove sites based on gene annotations
tx_db <- GenomicFeatures::makeTxDbFromGRanges(
  rtracklayer::import(fns$gtf)
)

mm_rse_filt <- remove_clustered_variants(
  mm_rse_filt, tx_db, variant_dist = 100
  ) |>
  remove_splice_variants(tx_db)

# calculate edit frequencies and depth
mm_rse_filt <- calc_edit_frequency(mm_rse_filt)

# filter on site depth >= 3 for all samples within replicates 
mm_rse_filt <- filter_replicates(
  assay(mm_rse_filt, "depth")[, 1:6],
  thresh = 3,
  n_rep = 3
)

# filter for edit_freq >= 0.05 for at least 3 samples
mm_rse_filt <- filter_replicates(
  assay(mm_rse_filt, "edit_freq")[, 1:6],
  thresh = 0.05,
  n_rep = 3
)

mm_rse_filt
```

Now do the same for chikv data â€” these may be a bit harsh for the virus coverage we have.

```{r filter_chikv}
chikv_rse_filt <- filter_replicates(
  assay(chikv_rse, "nVar")[, 1:6],
  thresh = 3,
  n_rep = 3
)

# calculate edit frequencies and depth
chikv_rse_filt <- calc_edit_frequency(chikv_rse_filt)

# filter on site depth >= 3 for all samples within replicates 
chikv_rse_filt <- filter_replicates(
  assay(chikv_rse_filt, "depth")[, 1:6],
  thresh = 3,
  n_rep = 3
)

# filter for edit_freq >= 0.05 for at least 3 samples
chikv_rse_filt <- filter_replicates(
  assay(chikv_rse_filt, "edit_freq")[, 1:6],
  thresh = 0.05,
  n_rep = 3
)

chikv_rse_filt
```

### annotation

Filter mm data by annotation, comparing to reference SNP and repeat databases.

```{r annotate_rse}
bed_to_gr <- function(x, name_col = 'name') {
  read_tsv(x, col_names = c('seqnames', 'start', 'end', name_col, 'score', 'strand')) |>
    plyranges::as_granges()
}

rmsk_db <- bed_to_gr(fns$rmsk_db, name_col = 'repName')
snp_db  <- bed_to_gr(fns$snp_db, name_col = 'snpId')

mm_rse_filt <- annot_from_gr(
  mm_rse_filt,
  rmsk_db,
  cols_to_map = "repName"
)

mm_rse_filt <- annot_from_gr(
  mm_rse_filt,
  snp_db,
  cols_to_map = "snpId"
)

# filter out simple repeats (having a '(' in the name) and anything with 'rich' in it. The rest
# seem to be high complexity repeats of specific classes.
keep_reps <- rowData(mm_rse_filt)[, 'repName'] |>
  str_detect(
    paste(c('\\(', 'rich'), collapse = '|'),
    negate = TRUE
  )
keep_reps[is.na(keep_reps)] <- TRUE

# filter out simple repeats and common variants (i.e., already a snpId)
mm_rse_filt <- mm_rse_filt[keep_reps, ]
mm_rse_filt <- mm_rse_filt[is.na(rowData(mm_rse_filt)$snpId)] 

mm_rse_filt
```

## Save filtered data

```{r eval=FALSE}
saveRDS(mm_rse_filt, path(ext_path, '/rds/mm_rse_filt.rds', compress = 'xz'))
saveRDS(chikv_rse_filt, path(ext_path, '/rds/chikv_rse_filt.rds', compress = 'xz'))

mm_rse_filt <- readRDS(path(ext_path, '/rds/mm_rse_filt.rds'))
chikv_rse_filt <- readRDS(path(ext_path, '/rds/chikv_rse_filt.rds'))
```

## Exploratory analysis

### Data tidying

```{r tidy_data}
var_raw_tbl <- assay(mm_rse, "Var") |>
  as.data.frame() |>
  rownames_to_column('site') |>
  as_tibble()

tidy_raw_var_tbl <- var_raw_tbl |>
  separate(site, into = c('chrom', 'pos', 'strand'), sep = '_') |>
  pivot_longer(-c(chrom, pos, strand)) |>
  separate(name, into = c('treat', 'rep'), sep = 1) |>
  filter(value != '-') |>
  filter(!str_detect(value, '^N'))

var_filt_tbl <- assay(mm_rse_filt, "Var") |>
  as.data.frame() |>
  rownames_to_column('site') |>
  as_tibble()

tidy_var_filt_tbl <- var_filt_tbl |>
  separate(site, into = c('chrom', 'pos', 'strand'), sep = '_') |>
  pivot_longer(-c(chrom, pos, strand)) |>
  separate(name, into = c('treat', 'rep'), sep = 1) |>
  filter(value != '-') |>
  filter(!str_detect(value, '^N'))

saveRDS(tidy_raw_var_tbl, path(ext_path, '/rds/tidy_raw_var_tbl.rds'))
saveRDS(tidy_filt_var_tbl, path(ext_path, '/rds/tidy_raw_var_tbl.rds'))
```

### Frequency calculations

```{r calc_freq}
# sum total number of edit sites in filtered data
filt_tot_valCounts <- tidy_var_tbl |>
  group_by(treat) |>
  dplyr::count(value)
  
tot_valCounts <- sum(filt_tot_valCounts$n) # total edit sites

#create tidy table of filtered data with frequencies calculated
filt_tbl <- filt_tot_valCounts |>
  mutate(freq = n/tot_valCounts, step = 'filtered') 

# raw data

raw_var_tbl <- assay(mm_rse, "Var") |>
  as.data.frame() |>
  rownames_to_column('site') |>
  as_tibble()

raw_tidy_var_tbl <- raw_var_tbl |>
  separate(site, into = c('chrom', 'pos', 'strand'), sep = '_') |>
  pivot_longer(-c(chrom, pos, strand)) |>
  separate(name, into = c('treat', 'rep'), sep = 1) |>
  filter(!str_detect(value, ',')) |>
  filter(value != '-') |>
  filter(!str_detect(value, '^N'))

# sum total number of edit sites in raw data
raw_tot_valCounts <- raw_tidy_var_tbl |>
  group_by(treat) |>
  dplyr::count(value)
  
tot_RawValCounts <- sum(raw_tot_valCounts$n) #total edit sites

raw_tbl <- raw_tot_valCounts |>
  filter(!str_detect(value, ',')) |>
  mutate(freq = n/tot_RawValCounts, step = 'raw') 
raw_tbl <- head(raw_tbl, -1) # removes non-categorized data

# combine
all_tbl <- bind_rows(filt_tbl, raw_tbl)

#calculate norm_freq
x1 <- pivot_wider(all_tbl, names_from = step, values_from = value) |>
  mutate(norm_freq = filtered / raw)
  
#plot number of edits by treatment  
tidy_var_tbl |>
  group_by(treat) |>
  dplyr::count(value) |>
  ggplot(aes(value, n)) + geom_col() + facet_grid(~treat)

```
 
 
#compare raw to filtered frequencies

# add column to each table for type of data (raw or filtered)
# calculate edit frequencies (freq) for each data (raw or filtered)
# merge tables
# pivot_wide (columns -> raw filt)
# calculate across rows normalized freq into a new column called normalized freq


 

